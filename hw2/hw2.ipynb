{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adf535ebe0215f8f7459cc1d4a2bda2e",
     "grade": false,
     "grade_id": "cell-5ae594183c2ba9fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 2: Perceptrons\n",
    "\n",
    "\n",
    "\n",
    "This assignment is due on Canvas by **11:59pm on Monday, April 10th**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://canvas.uchicago.edu/courses/49007).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda with Python 3.9. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit this Jupyter notebook **both** as a .ipynb file and a pdf to Canvas.  Do not compress either using tar, rar, zip, etc. \n",
    "- Extra credit questions will not make your homework total scores overflow i.e., not exceed 40% in the final grade. But you can use extra credit in one homework to cover another.\n",
    "\n",
    "**Acknowledgment** : Chris Ketelsen\n",
    "\n",
    "\n",
    "**Please put your name.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Name**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b661d22b2de3af882b4fc5a40210afe",
     "grade": false,
     "grade_id": "cell-831d67dea055c2cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd51ff36ed8450eaf739ccfe35bac53b",
     "grade": false,
     "grade_id": "cell-74dc2d431f34714c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [100 points] Problem 1 - Perceptron Training\n",
    "\n",
    "Consider a binary classification problem on the following dataset:\n",
    "\n",
    "| x1   | x2         | x3      | y| \n",
    "|:------:|:------------:| :-----------:|---:|\n",
    "|0|0|0|-1|\n",
    "|0|0|1|1|\n",
    "|0|1|0|1|\n",
    "|1|0|0|1|\n",
    "|0|1|1|-1|\n",
    "|1|1|0|-1|\n",
    "|1|0|1|-1|\n",
    "|1|1|1|1|\n",
    "\n",
    "We are going to experiment with the Perceptron algorithm in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f359c9d64af5b4a36c8e2b0f4be9de",
     "grade": false,
     "grade_id": "cell-8063e7270b6eedc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 1 [10 points]\n",
    "Complete the `perceptron_train` function and report the results.  \n",
    "[Note: for this part you should **not** randomly shuffle the order of the data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "365046976b8740444573218b20517901",
     "grade": false,
     "grade_id": "cell-3e62020d026f50d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not change - unless needed\n",
    "data = np.array([\n",
    "    [0, 0, 0, 1, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 1, 1, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 0, 1, 1],\n",
    "    [-1, 1, 1, 1, -1, -1, -1, 1]\n",
    "])\n",
    "data = np.transpose(data)\n",
    "# Initialize the weights and bias (note that we use a non-standard initialization here).\n",
    "weights = np.array([0, 0.5, 0.5])\n",
    "bias = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f45ab6376f88d9fe46b44f20f4dc7af",
     "grade": false,
     "grade_id": "cell-583db73f125b72af",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def perceptron_train(data, weights, bias):\n",
    "    \"\"\"\n",
    "    Train a perceptron algorithm and update weights and bias\n",
    "    :param data (array): data to train model on\n",
    "    :param weights (array): initial weights\n",
    "    :param bias (int): initial bias\n",
    "    \n",
    "    :type X: array\n",
    "    :type y: int\n",
    "    :rtype: weights (array), bias (int), number of mistakes (int)\n",
    "    \"\"\"\n",
    "    mistakes_count = 0\n",
    "    for row in data:\n",
    "        X = np.array(row[:3])\n",
    "        y = row[-1]\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return weights, bias, mistakes_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc542d7bd8637851da60f99171affc5d",
     "grade": false,
     "grade_id": "cell-1d2387cfaf34ed49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 1 A [5 points]\n",
    "Report the weights, bias, and number of mistakes after the first epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa772438f15187642c3bf0303aef679f",
     "grade": false,
     "grade_id": "cell-254f1f918dd02cfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Do not change or remove this code\n",
    "weights, bias, number_of_mistakes = perceptron_train(data, weights, bias)\n",
    "print(f'weights: {weights}, bias: {bias}, mistakes: {number_of_mistakes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ff7b16f06bf7c686a000ebe909e9b7d",
     "grade": true,
     "grade_id": "cell-71a254a22738d8dd",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# for grading - ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88fac91d7af9e59f524cd602252824c3",
     "grade": false,
     "grade_id": "cell-ec32d4a96188a96d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 1 B [5 points]:\n",
    "Run the perceptron training for 50 more epochs with the updated weights and report the weights, bias and number of mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac6b3485d7a8339a44998a1b549c3dba",
     "grade": false,
     "grade_id": "cell-9162930c9497743a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "print(f'weights: {weights}, bias: {bias}, mistakes: {number_of_mistakes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d827d6ff8b0d95915a4c0f356e9881b",
     "grade": true,
     "grade_id": "cell-959e42c284018b8d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# for grading - ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56994a0870a43280fa8ea21b46fc8f8d",
     "grade": false,
     "grade_id": "cell-fdb42b2a6b9cefea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part 2 [10 points] \n",
    "Is it possible that your Perceptron classifier would \n",
    "ever perfectly classify all training examples after more passes of the Perceptron Algorithm?\n",
    "Clearly explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef7f7ce9a1ee2fe9a9eee481b2f6196a",
     "grade": true,
     "grade_id": "cell-9e4148ad96554da5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9f2807abe406c501ba4338847797330",
     "grade": false,
     "grade_id": "cell-91fc1b93bd24f56d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part 3 [10 points] \n",
    "Does the Perceptron classifier necessarily make the same number of mistakes after the first epoch if the data is presented in any other randomized order? \n",
    "    Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe732b80f0e2e9a51d9f6e475f36b19e",
     "grade": true,
     "grade_id": "cell-47e30b7cd8370b85",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ccc34cf58aa1a817ef82e01f2768c72",
     "grade": false,
     "grade_id": "cell-571944605a5a58ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Part 4 [45 Points]:  Perceptron Classifier on random generated data\n",
    "\n",
    "Update the Perceptron Learning Algorithm to explore the convergence on linearly separable simulated data sets with particular properties. Take a look at the `Perceptron` class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87e1f15915ea4e8fbb247be34f5b5475",
     "grade": false,
     "grade_id": "cell-7770ef2854032d8b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Class to fit a perceptron classifier to simulated data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=100, margin=0.1, X=None, y=None, random_state=1241):\n",
    "        \"\"\"\n",
    "        Initializes Perceptron class.  Generates training data and sets parameters. \n",
    "\n",
    "        :param n (int): the number of training examples\n",
    "        :param margin (float): the margin between decision boundary and data\n",
    "        :param random_state: seed for random number generator \n",
    "        :param X (array): Input training features.  Only used for unit testing. \n",
    "        :param y (array): Input training labels.  Only used for unit testing. \n",
    "        \"\"\"\n",
    "        # initalize random seed\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        # initialize parameters\n",
    "        self.n, self.M = n, margin\n",
    "\n",
    "        # generate random simulated data\n",
    "        self.X_train, self.y_train = self.gen_data()\n",
    "\n",
    "        # only used for unit tests\n",
    "        if X is not None and y is not None:\n",
    "            self.X_train, self.y_train, self.n = X, y, X.shape[0]\n",
    "\n",
    "        # initialize weights and bias\n",
    "        self.w = np.array([1.0, 0.0])\n",
    "        self.b = 0\n",
    "\n",
    "        # initialize total mistake counter\n",
    "        self.num_mistakes = 0\n",
    "\n",
    "    def train(self, max_epochs=100):\n",
    "        \"\"\"\n",
    "        Runs the Perceptron Algorithm until all training data is correctly classified. \n",
    "\n",
    "        :param max_epochs (int): Maximum number of epochs to perform before stopping.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def plot_model(self, decision_boundary=False):\n",
    "        \"\"\"\n",
    "        Plots the simulated data and the learned decision boundary\n",
    "        \n",
    "        :param decision_boundary (bool): whether to plot the decision boundary\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 8))\n",
    "        colors = [\"steelblue\" if yi == -\n",
    "                  1 else \"#a76c6e\" for yi in self.y_train]\n",
    "        ax.scatter(self.X_train[:, 0], self.X_train[:, 1], color=colors, s=75)\n",
    "        if decision_boundary:\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        ax.grid(alpha=0.25)\n",
    "        ax.set_xlabel(r\"$x_1$\", fontsize=16)\n",
    "        ax.set_ylabel(r\"$x_2$\", fontsize=16)\n",
    "\n",
    "    def gen_data(self):\n",
    "        \"\"\"\n",
    "        Generate random linearly separable data with given margin. \n",
    "        Note: You should not need to change this function \n",
    "        \"\"\"\n",
    "        flip = np.random.choice([-1, 1])\n",
    "        pos_x1 = np.random.uniform(-1 / np.sqrt(2), 1 / np.sqrt(2), int(self.n / 2))\n",
    "        pos_x2 = np.random.uniform(\n",
    "            self.M + flip * 0.1, 1 / np.sqrt(2), int(self.n / 2))\n",
    "        pos_x2[-1] = self.M + flip * 0.1\n",
    "        neg_x1 = np.random.uniform(-1 / np.sqrt(2), 1 / np.sqrt(2), int(self.n / 2))\n",
    "        neg_x2 = np.random.uniform(-1 / np.sqrt(2), -\n",
    "                                   self.M + flip * 0.1, int(self.n / 2))\n",
    "        neg_x2[-1] = -self.M + flip * 0.1\n",
    "        X = np.concatenate((np.column_stack((pos_x1, pos_x2)),\n",
    "                            np.column_stack((neg_x1, neg_x2))))\n",
    "        X = np.dot(X, np.array(\n",
    "            [[np.cos(np.pi / 6), np.sin(np.pi / 6)], [-np.sin(np.pi / 6), np.cos(np.pi / 6)]]))\n",
    "        y = np.array([+1] * int(self.n / 2) + [-1] * int(self.n / 2))\n",
    "        rand_order = np.random.choice(\n",
    "            range(self.n), replace=False, size=self.n)\n",
    "        return X[rand_order], y[rand_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bba29ae169a9590923c3cdb8ec9d57e5",
     "grade": false,
     "grade_id": "cell-a686c48925c47ad0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 4 A [10 points]\n",
    "The `Perceptron` class above has the capability of generating its own training data with certain properties. Execute the cell below to generate $n=100$ simulated training examples and plot them. Experiment with the `margin` parameter (good values to try are between $0.01$ and $0.4$). Explain what the `margin` parameter is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2 # subject to experiment\n",
    "perc = Perceptron(n=100, margin=margin)\n",
    "perc.plot_model(decision_boundary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17feb7e426f319917df17bea1f1ed7a0",
     "grade": true,
     "grade_id": "cell-788872a24aff264a",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": false
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfc82d86b06fef32726c5c4b6126009e",
     "grade": false,
     "grade_id": "cell-6dfc5cb5c8b88c55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 4 B [20 points] \n",
    "Modify the `train` method in the `Perceptron` class to perform the Perceptron Learning Algorithm and learn weights ${\\bf w}$ and bias $b$ that perfectly classify the linearly separable training data. Your implementation should:\n",
    "\n",
    "- Visit all training examples in a random shuffled order over each training epoch. (**Note:** np.random.shuffle() will be helpful here)\n",
    "- Terminate when you finish an epoch without making a single classification error or when you hit the maximum number of epochs.\n",
    "- Use the `self.num_mistakes` counter to count the total number of classification errors over the entire training process. (**Note:** You should also have a seperate counter variable for keeping track of mistakes within each epoch.)\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "You should **not** use Scikit-Learn's Perceptron object in your solution.\n",
    "It's a good idea to implement a stopping criterion based on the `max_epochs` parameter as the first step. Later we'll look at training sets that will terminate on their own, but implementing a stopping mechanism will save you some pain in the development process.\n",
    "Do not change the initial guess for the weights and bias. These values were chosen to match the example done in lecture for the unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6860e8c4a3f5829d0f68470fc04e9cb6",
     "grade": true,
     "grade_id": "cell-ad1677859c4ce262",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite('prob 1.4B', Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb73f1dbfe5d02e9087d5488a8a981c4",
     "grade": false,
     "grade_id": "cell-36d78a28960b4f81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 4 C [15 points]\n",
    "Modify the `plot_model` method so that it plots the learned decision boundary with the training data. Demonstrate that your method is working by training a perceptron with a margin of your choice and displaying the resulting plot. What is the equation of the learned decision boundary? (Use symbols not numbers.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a79205ea4f2a84684e9601273901f82",
     "grade": true,
     "grade_id": "cell-807e6237e11d03ed",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = Perceptron(n=100, margin=0.2)\n",
    "perc.train()\n",
    "perc.plot_model(decision_boundary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8ea5fda17e81aa2ec1ca3c452abdb7c",
     "grade": false,
     "grade_id": "cell-637d0b72a2dec574",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 5 [25 points]\n",
    "\n",
    "Verify the theorem which states that, if you train a perceptron on linearly separable training data with margin $M > 0$ and each training point satisfies $\\|{\\bf x}\\|_2 \\leq 1$ then the Perceptron algorithm will complete after making at most $1/M^2$ classification mistakes.\n",
    "\n",
    "Do the following to verify the above statement: \n",
    "- Train perceptrons with $n = 100$ and different margins ($M=0.3, 0.1, 0.01, 0.001,$ and $0.0001$).\n",
    "- Produce a log-log plot with $1/M$ on the horizontal axis and the total numbers of mistakes on the vertical axis. \n",
    "- On the same set of axes, plot the theoretical upper bound on the number of training mistakes.\n",
    "\n",
    "Usually we run multiple simulations and get an averaged total number of mistakes for each margin, but it is fine if you only do one simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8ef031fa3c7ae9bd1a3a4b1ce5639f0",
     "grade": true,
     "grade_id": "cell-5eb12c673017afa0",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Optional survey.\n",
    "***\n",
    "\n",
    "We are always interested in your feedback. At the end of each homework, there is a simple anonymous feedback [survey](https://docs.google.com/forms/d/e/1FAIpQLSdIXy89cVkBdXpUr43ea0FmdIYTIfuDdMY7sItz_GU6Ovjsfg/viewform?usp=sf_link) to solicit your feedback for how to improve the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "396.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
